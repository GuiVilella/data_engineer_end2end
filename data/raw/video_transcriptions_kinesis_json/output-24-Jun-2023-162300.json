{"data": "{\"value\":\"0.0 Hello, this is a comprehensive paper review on the paper called memory assisted prompt editing6.166.16 to improve GPT-3 after deployment. As the title says, this paper is really cool because it is12.3212.32 able to improve these large language models after they're deployed. So this video right here is a18.08000000000000218.080000000000002 comprehensive review on the paper. After you've watched the video, you'll have a good idea of23.623.6 what the method does, what it is and what the paper describes. The next video released tomorrow29.1229.12 will be an interview with the authors of the paper. And that is also really cool. And I35.0435.04 definitely learned a lot from that as well. So I invite you to check out both. And I'll see you40.8840.88 around. Have fun. Hey there, today's sponsor is the course on introduction to graph neural networks.47.4447.44 This is a course by my friend Zach Joest, who is an expert in graph neural networks. He's packed52.852.8 all his knowledge into one course that will educate you on both the theoretical and hands on59.1259.12 practical aspect on graph neural networks. Graph neural networks are really important. They're64.1664.16 definitely one of the most interesting areas in deep learning right now. They've also powered a69.669.6 lot of recent advances in scientific breakthroughs, such as alpha fold protein structure predictions,76.3276.32 or better traffic predictions. If you use my link, you'll get a 15% discount on the course83.683.6 enrollment is open right now and lasts until April 1 or until spaces run out. Alright, let's90.4799999999999990.47999999999999 get into the video now. See ya. Hello there. Today we're looking at memory assisted prompt editing97.1199999999999997.11999999999999 to improve GPT three after deployment by Amon Madan, Niket Tandon and others. So this paper104.47999999999999104.48 proposes a method to improve GPT three in an interactive mode in a user feedback mode. Here112.0112.0 is a little sample of how that could look like. So the user would pose a question to GPT three,118.80000000000001118.80000000000001 for example, what word is similar to good. And this is not displayed here. But in advance of126.96000000000001126.96000000000001 that there'd be like an entire prompt like you would be used to for prompting GPT three. If you133.36133.36 don't know about GPT three, I've made a video on GPT three extensively describing how that works and139.92000000000002139.92000000000002 how to construct these prompts right here. So that GPT three gives you what you want, supposedly,146.4146.4 because it doesn't always work. For example, here, the user asks, what word is similar to good. And152.56152.56 GPT three says the homonym of good is wood, which is kind of true. But the user doesn't is not161.44000000000003161.44 specified clearly what similar means the user here had a different intent, which then the user168.07999999999998168.07999999999998 specifies the user says similar to means with a similar meaning. So the user didn't mean a word176.16176.16 that sounded like good, which is wood, the word the user meant a word that is kind of like a182.64182.64 similar synonym instead of a homonym. So in this new system, this thing right here would be called190.72190.72 feedback, and the user would be able to give this feedback to GPT three. And then GPT three would197.6197.6 write that to memory, it's not actually GPT three, it's sort of like a plugin that the paper develops.204.32205.52 And then the user, the next time the user asks, for example, what word is similar to surprised,212.72213.68 the system will remember that the last time the user asked the question like that, like similar to219.2219.2 you know, what word is similar to another word, the system will go back to the memory, retrieve225.6225.6 the feedback right here, put it into the prompt, and then guides GPT three to actually to actually233.76234.39999999999998 answer in the correct way. And so GPT three here says the synonym of surprised is amazed. So241.28241.28 multiple things to see right here. First of all, their plugin, the system that the paper here247.51999999999998247.52 proposes can be added to any pre trained language model. And the language model itself doesn't have253.52253.52 to be changed, which is really important for something like GPT three, because that's too big258.48258.48 to to change, I guess you can fine tune it. But you need a lot more data than just two or three265.44265.44 examples. The other thing is that it is interactive. So this is an interactive user session where the274.16274.16 user can specify not only clarifications for things that are clearly wrong, but also maybe279.6279.6 personal preferences. So this is goes beyond what this paper shows. This paper is mostly about286.8287.68 either factual accuracy, like accuracy of the task or figuring out user intent from ambiguous294.56294.56 meanings. This could easily be used to personalize interaction with GPT three for particular users301.92301.92 by interactively letting them improve the system. This is kind of like what you know, normies think308.64000000000004308.64000000000004 of AI is like a system that learns from the two or three times they give it feedback and then gets314.32314.32 better over time. So this is pretty cool. And lastly, what was I gonna say? Um, I don't I don't321.52000000000004321.52000000000004 remember anymore. But we're going to look at how this works. And you know, what's good about it?327.84000000000003327.84 What's bad about it? And yeah, that's that's about it. So here is the proposed before and after336.47999999999996336.47999999999996 of the system. If the user with no memory asks GPT three, the user gives an X. As we said, it's344.15999999999997344.15999999999997 it's always prefixed with some sort of a prompt that guides GPT three into giving the correct350.55999999999995350.56 answer structure or type of answer. If we're going to look at some of these prompts in just a second,357.6358.32 and GPT three will give some sort of an answer. Now, this might be good or bad, as you may have365.2365.2 seen, it can turn out not the in the best way. So in their memory enhanced GPT three example,373.44373.44 the user would give a question x. Now let's disregard the memory for now. Let's just go380.4380.4 directly to GPT three, which is what happens in the very first iteration of this interaction. So386.72386.72 GPT three now has a prompt in front of it as well, but a prompt that the author is here designed,392.72392.72 such that GPT three doesn't only give the answer to the question, but also you the understanding399.36399.36 of what the user meant. So up here, you can see that by GPT three answers, the homonym of good407.6407.6 is wood, right? GPT three doesn't just answer wood, which would be the answer. But also this413.76413.76 first part right here, which is this understanding. So the authors construct the sort of meta prompt421.36421.36 that they give. And that instructs GPT three not only to to give the answer, but also to give the428.56428.56 understanding like a clear, a clear output of what it understood. The user can then take that436.16436.8 and decide if that's what the user wanted or not. So if the user is happy, then all is good. If the443.44443.44 user is not happy, the user can give feedback to GPT three, the user gives feedback in kind of in450.16450.16 natural language, just like types it up like, no, I didn't mean this, I meant this other thing.455.52455.52 And you have to type it up in a bit of a special way, you have to type it up, you can't just say461.03999999999996461.03999999999996 no. I guess you can. But it's best if you write like similar to means with a similar meaning. So470.08470.08 you clarify your original question right here. And by doing that, you committed to the memory.478.08478.08 Now, obviously, what you could do is you could simply add that clarification to the prompt, go484.8484.8 back to GPT three, and actually let it answer correctly, which would work. But we're not only491.36491.36 about this prompt. The idea here is that this feedback will help guide GPT three in all499.03999999999996499.03999999999996 subsequent prompts, because the user is likely going to express themselves in the same way. GPT506.64506.64 three, if it misunderstood is likely going to misunderstand in the same way. So this memory512.8512.8 serves as a bit of a generalizable correction mechanism that learns from few items of feedback.520.24521.04 So let's let's look what happens the second time around. So the second time the user again has a526.0526.0 question x, we then go first to the memory and we see, or x prime, let's call that x prime, we see,533.04533.04 is there anything in the memory that is similar to x prime, meaning that is there any question540.7199999999999540.7199999999999 before that has been submitted to GPT three in the current session doesn't need to be in the same546.8546.8 prompt or anything just in the current user session that has been misunderstood. So do we have554.8554.8 an instance that is close to x prime, where feedback was given, that would be part of the561.52561.52 memory. And this is being done with either semantic similarity, sort of, so you take some sort of a569.4399999999999570.16 of a language model or some sort of a sequence model, for example, a transformer, you look at576.0799999999999576.0799999999999 the embeddings of the sentences you compare them via cosine similarity, you can also do word581.36581.36 overlap, or something like this. But what you want to do is you want to retrieve those instances of586.24586.24 feedback. And then you want to add that feedback to the prompt. In the very case in the case that594.16594.16 you so this is hidden here. This is hidden, it just says and adds to prompt and we're going to see600.64600.64 how this happens how the system adds that to the prompt. It's actually quite simple. It's mainly a606.96606.96 it's mainly a concatenation adds it to the prompt. So the users, this is the x prime right here, the x prime is being augmented with the feedback that the user has given previously, and then submitted to GPT-3. And with that feedback, GPT-3 is now able to actually more likely give the correct answer. And if, you know, if it's misunderstood, the user can give feedback again. And that's the631.52631.52 the end. So give a little signal and if, if it's misunderstood, the user can give feedback again.637.1999999999999638.24 And that would make it even better in the next few iterations. So this is the overarching system the644.4644.4 paper makes pretty clear that it doesn't propose like it doesn't purport to be the state of the art651.28651.28 or the the final the final system in this framework, it simply wants to present a framework.658.16658.16 that's it states that I think two times or more. Now, there I have mixed opinions on papers that666.0666.0 say, well, we just want to present a framework. On the one hand, it's obviously good to present672.0799999999999672.0799999999999 a framework. Your papers like papers shouldn't be rejected, if they have a good idea for a new679.52679.52 framework, just because they can't get it to, you know, be super duper performant.684.8684.8 On the other hand, saying, you know, we just want to propose a framework is very often,691.04691.04 it's either like a cop out for not reaching good numbers, or just kind of like, you know, we,698.64699.4399999999999 we want to split one paper into two papers, because the next paper is going to be sort of the705.4399999999999705.4399999999999 well performing thing. Or it just, there's a danger that it's not super well thought through,712.9599999999999712.96 because the authors haven't actually put in like massive efforts into making this good,718.8000000000001718.8000000000001 at which point, many flaws reveal themselves in these types of frameworks. But the framework's724.32724.32 pretty general. So, you know, we'll give them we'll give them that. They claim Yeah, so this is731.6800000000001732.48 what I just explained, they maintain a memory m of feedback as a set of key value pairs. The key is740.0740.0 a misunderstood question, and the value is the user's feedback to correct that misunderstanding.745.68746.64 Given a new question, we check if the model has made a mistake on a similar question earlier,752.48753.28 by querying the memory for a similar question, if found append the corresponding feedback to the759.44759.44 question prompt. And the here's where they say, not definitive, rather our main contribution is766.32766.32 the general framework itself suggesting how user feedback might continuously improve model770.8000000000001770.8000000000001 performance without retraining in a few short prompt setting. So let's look in in a little bit778.5600000000001778.5600000000001 more detail into the system, that the system has four distinct parts, this memory that we've just785.5200000000001785.5200000000001 talked about, that's a growing table of key value pairs, the key being questions that have been791.2791.2 misunderstood, and the value being user feedback. So obviously, the user only chooses to give feedback799.12799.12 if the user was misunderstood. And therefore, the memory only contains those things. There's a look806.24806.24 up function, which I guess is the most complicated or most complex or complicated, which I'm too815.2815.2 ah, I'm too surraged. The most complicated of the functions right here, it's they call it a learned823.76823.76 retriever that matches the query against all the keys of M. So that's where we retrieve similar831.5200000000001831.5200000000001 prompts that have been misunderstood in the past. And as I said, we can do that with a pre trained838.32838.32 embedding, for example, of a transformer model, or any, any sort of embedding model for text, or any846.4000000000001846.4000000000001 other thing, they use Levenstein distance for some experiments. So the combiner is a gating function854.6400000000001854.6400000000001 allowing irrelevant retrieved feedback to be ignored. I don't I don't think they actually do.859.7600000000001861.12 I don't think they do that right now to ignore irrelevant feedback, other than thresholding867.2800000000001867.28 the lookup function. So the lookup function is an inner product. And I guess the combiner is the872.24872.24 threshold on that inner product, the prompter here, it passes the output of the combiner to881.1999999999999881.1999999999999 the prompt. And so that in our case, this is just going to be a concatenation of the prompt888.56888.56 and whatever the combiner outputs. So it's going to be the prompt plus the question if there was895.92895.92 nothing found in the memory, or the prompt plus the question plus the feedback if it was found in memory.902.3199999999999903.8399999999999 So I would add, yeah, let's let's get into the task. And then we'll get into the actual examples.911.5999999999999911.5999999999999 So they have two kinds of tasks. The first kind of tasks, there are five tasks that are broadly in917.28917.28 the category of word scrambling and manipulation, for example, to reorder some letters, these are924.7199999999999924.72 reordered in exact reverse. Other there are other there are anagram one, anagram two, and so on.932.88933.6800000000001 There are very various tasks, five of these, and there are five lexical QA tasks,940.48940.48 which are asking GPT-3 for a synonym, for an antonym, for a homonym, and so on.945.6800000000001945.68 They say for each task, the prompt contains a few different variations. For example, what is the954.16954.16 homonym of a word? What sounds like the word? They create a data set. So this is where, yeah,964.88964.88 we'll get to that as well. They create a data set of samples, feedback, understanding and the972.9599999999999972.96 solution. So essentially, without the feedback, this would be what you would give to GPT-3 as a979.2800000000001979.2800000000001 prompt. They also collect feedback so they can simulate users. So they, they, they give the x988.0988.0 to GPT-3. And if it is misunderstood, they do that in a they determine that in a heuristic way,994.72994.72 they also provide the feedback to the memory. They come up with sort of invented data,1000.961000.96 with sort of invented data of users being understood or misunderstood.1006.081010.0 The, yeah, the retriever, as I already said, is either a semantic similarity using the cosine1015.61015.6 distance with a threshold, or a lexical similarity and heuristics for similarity matching.1021.121021.12 The combiner concatenates x and the feedback received by the retriever. And the prompter1029.041029.04 concatenates the prompt and whatever the combiner outputs. We didn't have one of them though. Oh,1038.81038.8 no, the combiner is the gating function. Okay, that doesn't, it doesn't seem like much of a1044.561044.56 gating function. Yeah, so I want to jump over the results quite quickly to show you some examples1051.761051.76 of how that even might look like. So here is a prompt for the tasks. I think these are the lexical,1064.721064.72 the lexical QA tasks. So asking for antonyms and homonyms. This is the entire thing that you would1071.21071.2 give to GPT-3 in front of your question. So you would append your question down here somewhere,1078.721078.72 like below the prompt in the same style as the prompt. So this is, this is, this is how you query1088.41088.4 GPT-3. What you would do is you would simply give some examples and prime GPT-3 to continue the1097.12000000000011097.12 pattern. So they hear, they ask, what is the homonym for ring? The homonym for ring is ring.1105.121105.76 Now these are all human generated, right? All of these are human generated. So you prime GPT-3 to,1111.841111.84 you know, what, how, how questions are asked, and how answers are given. The important thing1119.841119.84 right here to see is that all of the answer patterns they provide is, it's not just the,1126.95999999999981128.32 the answer, for example, permit is the antonym for prohibition. The answer also contains this1138.721138.72 understanding part, this thing right here, the antonym for prohibition is, that's the understanding,1145.761145.76 that's the understanding. And this right here is the label. This is important, because the1154.41154.4 understanding is what the user uses to decide whether or not GPT-3 has understood the question.1160.87999999999991162.0 What they also do later in the same prompt, they, as you can see, they also add1168.321168.32 questions with feedback. So here you see how they incorporate the feedback. There's like this,1174.081174.08 I don't know what that's called, a pipe symbol. And then it says clarification, colon, and then1181.521181.52 this here is the feedback. Okay, so this is also part of the prompt. So the prompt contains some1187.761187.76 generic feedback, where there is some sort of an unclear or ambiguous question, then there is1195.91999999999981195.92 feedback, and then there is the correct answer that is based on the feedback. So1201.921204.24 you can see right here, the question is, and that's pretty special, the question is,1207.761208.5600000000002 or up here, it says, what is the synonym for right? And then the answer is the synonym for1214.961214.96 is. So it always goes after the question, how the question is formulated, the understanding goes1222.481222.48 after the question. However, they prime GPT-3 that if there is a clarification, you can see that1229.281230.0 the answer goes sometimes partially, sometimes fully on the clarification. What I mean by goes1239.21239.2 on, I mean, it, it refers to so the understanding reflects the clarification that allows multiple1249.441249.44 things it allows, if the user is still not understood, it allows the user to give feedback1256.01256.0 again. And also, it primes GPT-3 to actually pay attention to this clarification part.1263.441264.64 So in the prompt, you'll get a bunch of these clarifications to teach GPT-3 how to include1273.21273.2 these clarifications in its output. This is pretty smart it so the prompt is not only a prompt for1282.561283.76 what kind of answers you want, the prompt is also a prompt for this understanding part, which is a1290.08000000000021290.0800000000002 necessary precondition of making the of making the system interactive. And the prompt also includes1300.08000000000021300.08 the next step of the interactivity and how to react to it. This is, I think this is a good1308.39999999999991308.3999999999999 piece of prompt engineering. People are getting better at this by the day. So this is, this is1316.961316.96 before the question even gets here. So the question would be added here. And if there is1322.961322.96 feedback in the memory, the feedback would obviously be a pendant with a pipe symbol,1327.61327.6 then clarification, and then the feedback would be added here. And then GPT-3 would be prompted to1334.481334.48 give its answer right here. You can see if there is something in the memory, GPT-3 already knows1342.241342.24 how to use these clarification parts right here. So it's pretty good. Yeah, that's there, there are1351.041351.04 a bunch of examples, you can we can we can maybe look at them or you can look at them. What I want1357.61357.6 to look at lastly, is the data set generation. So they simply say that they created a data set,1367.681368.24 we manually created 15 tasks templates with three variants of phrasing the question for each task.1373.841373.84 You know, this is this is fine. This is prompt engineering. They also, they also do come up with1385.19999999999981385.1999999999998 sort of the variations for the feedback. Where have I data sets templates, phrasing each question.1395.521395.52 Okay, I cannot, I can't come up with but it is my understanding that they create the entire data1407.361407.36 set. So they create the prompts, and then the tasks they get from other papers, for example,1413.841414.6399999999999 the synonyms, the homonyms and so on, they get from other data sets that other papers1419.521419.52 have as well. But then the feedback, the feedback, they also do themselves and there is a danger1426.721426.72 right here, because they create the task samples for prompting right. And also us here, here, they1434.87999999999991436.16 they create, they create the prompts, they create the task samples for the prompts, they also create1442.321442.32 the example feedbacks, and they create the data set of feedbacks, which is dangerous, because1451.041451.84 that might lead to, you know, me just kind of formulating these tasks at templates, not as1459.21459.2 accurately as you know, maybe I could. And then obviously, once I clarify, I get an improvement1466.87999999999991466.88 So the data set creation here, if I understand it correctly, being manual is a big interference,1476.481476.48 I guess, just from a research standpoint, with the researchers interest, like there's a conflict of1483.52000000000021483.5200000000002 interest in making this data set and what you want to get out of the data set. So that is just1490.481490.48 one concern that I would have right here. The other concern, as you can see, is if you're,1498.481499.1200000000001 if you're retrieved clarification from the memory, so this thing here comes from the memory,1504.481505.1200000000001 if that is wrong, like, if it's actually not related to the question right here,1510.161510.48 then things could go bad, because GPT-3, you know, it's a very, very, very, very, very, very,1519.041519.04 because GPT-3, given the prompt is explicitly trained to address whatever is in the clarification1526.481526.8799999999999 in its answer. And that could be not not super duper1532.561534.1599999999999 relevant, it could actually be destructive. So GBD-3 could be completely correct in answering1540.39999999999991540.3999999999999 the question, yet, if the clarification is wrong, it could output a wrong answer. And that's not1548.63999999999991548.64 not entirely, you know, that's not entirely good. Or maybe,1554.761555.18 maybe I've misunderstood something, because what I can1559.21559.2 also imagine is that the memory contents are somehow appended to1569.08000000000021569.0800000000002 the prompt itself. So the question and the clarification,1573.28000000000021573.96 which, and that's what I don't know. And that's what I would1577.28000000000021577.28 like to ask the authors, because it's not entirely clear to me1581.281581.72 what they do. They compare two different baselines right here.1585.681585.68 And it could also be that the baselines implement some of what1589.39999999999991589.3999999999999 I just said. So for example, let's go here, the no mem,1594.87999999999991594.92 that's just GPT-3. Then there is the grow prompt and grow prompt1599.561600.2 says the prompt is continuously grown with a subset of memory M1606.21606.2 that can fit within the prompt. So I think this grow prompt1610.51610.5 thing right here, that's where I have my prompts that we've just1613.821613.82 seen. And then I would just add like all the entries of M or as1617.86000000000011617.8600000000001 many as I could here. And then I would add x. So there will be no1622.761622.78 clarification over here for x never in this grow prompt, it1626.781626.78 would just be that this portion of memory here grows and there1631.58000000000021631.58 would always be an x and the clarification or a feedback FB and1636.461636.46 an x and an FB. So all the things that I've gotten wrong in1640.93999999999981640.9399999999998 the past would be appended here as pairs of sample and feedback.1646.821647.82 And then this is compared to this mem prompt system. That's1653.341653.34 the system that they have. Now again, it is not clear to me,1657.581657.58 because tech like is not clear to me if their system simply1662.221662.26 retrieves the most relevant unit here and appends it here1666.981666.98 instead of the M. So or maybe the all the relevant units,1672.541672.58 right? In which case there would also be no feedback here, or if1677.861677.86 their system retrieves the most relevant thing, and then appends1681.89999999999991681.9 only the feedback to the x right here. I don't know. Like I don't1688.30000000000021688.3000000000002 know. It concatenates C at the end of P and C concatenates x1698.181698.22 and the feedback retrieved. So I'm pretty I'm pretty sure. I'm1704.71704.7 pretty sure that it's the second one it appends the concatenates1709.021709.02 the feedback to x. However, here it says they use a cosine1713.981713.98 distance with a threshold of point nine. There is no mention1717.861717.9 of like a maximum. Like they retrieve the maximum feedback.1723.91724.06 It seems like this could result in an entire set of feedbacks.1727.31729.34 Yeah, but I don't want to go too deep into that. I think I've1732.661732.66 understood correctly. The danger here is that the green stuff,1737.061737.06 like the grow prompt, the way understand is not like a perfect1740.17999999999981740.1799999999998 baseline for what they do, because the grow prompt inserts1744.061744.34 the memory samples as such with the original questions, and1748.41999999999981748.4199999999998 their system only inserts the it only inserts the feedback after1755.781755.78 the question that's currently happening. So either we need a1760.061760.06 baseline that also adds only feedback right here, but1764.51764.5 selected in a maybe less smart way. Or we need as a baseline a1769.581769.58 system that selects the feedback in a smart way, but then then1774.181774.18 tries to prepend the original question with that feedback in1779.91779.9 front of x and leave x without feedback or without1783.741783.74 clarification. So I think, you know, just baseline wise, that1789.221789.22 that is what would be needed. But you can see in their experiments,1794.51795.46 they show, I guess convincingly, that they are able to improve1800.581800.58 the accuracy. These are our steps, these are not training1803.221803.22 steps, these are steps of interaction with the system. So1807.541807.66 the system is never trained, it's simply interacted with and1810.86000000000011810.8600000000001 this memory is filled up. You can see, interestingly, at the1815.261815.26 beginning, everything fails. Which, which is interesting,1821.221821.22 right? Because one would expect that at least this mem prompt1826.621826.62 system would remain the same, I guess GPT three remains the1830.821830.82 same, but but the mem prompt system also declines. Now, if1835.91836.18 the retriever is pre trained and fixed, and the threshold is1842.541842.54 selected, well, it should not retrieve any question, any1846.861846.86 clarifications that have nothing to do with the question. So the1850.461850.46 performance in my mind shouldn't sink this dramatically, which1855.37999999999991855.3799999999999 tells me that the the max function is just very important.1860.51860.5 So they they probably mostly get the most relevant feedback. If1867.421867.42 it has if it passes the threshold, and here is what happens, I could1873.261873.26 guess if that feedback is irrelevant. So the it would1878.781878.78 actually biased language model towards giving the wrong answer.1882.30000000000021882.5 And only after a while do I have enough feedback collected that I1886.381886.54 sort of accurately cover what I would like to ask. Yeah, you can1892.91892.9 see how this this gets, I guess, problematic as soon as your1897.661897.66 domain of requests to GPT three increases, because there's1905.181905.18 probably probably doesn't need to be a huge domain before you1909.62000000000011909.6200000000001 start to overcorrect for things, but then you might also just1913.54000000000021913.5400000000002 tighten your threshold. So you know, what do I know? However,1918.141918.14 you know, disregarding correcting things, personalization, I think1923.421923.46 might be just a really neat application of this, to just1928.261928.26 sort of nudge, nudge GPT three into a personalized interaction1934.58000000000021934.6200000000001 with the user. And if it misunderstands there, then it's,1938.58000000000021938.7800000000002 I would guess it's more mild than here where it was just kind1943.82000000000021943.82 of like, it essentially negates an output essentially says no,1948.261948.26 that's wrong. What's also interesting is that the grow1952.061952.06 prompt never reaches the potential again, we don't know1956.021956.02 if that is because it's a different structured prompt. But1960.13999999999991960.1799999999998 at least it's partially due to the fact that it's not smartly1963.261963.26 selected, it simply appends to whatever is last in the last few1967.41999999999981967.4199999999998 things in the memory. Also, interestingly, this mem prompt1972.821972.82 where the probability of giving feedback is point five, it is1977.861977.86 kind of bad at the beginning. So here, the probability of getting1983.061983.06 feedback from the memory is only half. So half the time, the1987.621987.62 memory would have something, but you're not you're not getting1992.061992.06 it. This is kind of like an artificial limitation on the1995.31995.3 system, just your retriever might be bad, not recognize that1998.461998.46 there's something there. Interestingly, this also grows2001.982001.98 to the same performance. And I wonder why wouldn't I expect2006.422006.42 this to be, you know, only half the gains, because it only in2011.462011.5 half the time, it actually gets any clarification. So half the2017.542017.54 time, GPT-3 would still output the wrong answer. I might2023.422023.42 confuse, I might confuse something here, but it seems to2027.982027.98 me that that's what should happen, they shouldn't end up at2032.32032.34 like almost the same performance. So that is the2038.542038.58 overview largely over the results, they have these other2041.662041.66 tasks as well, they're much kind of less clear. They say, well,2046.62000000000012046.6200000000001 there's not too many ways to misunderstand in, please turn a2050.422050.42 word around or so. They also do experiments in low resource2055.582055.58 languages, which is also cool, turns out about the same as you2059.342059.34 can see right here. So in conclusion, I think this is a2064.062064.1 neat idea. I like that it is essentially a suggestion on how2071.92071.9 to personalize these language models or how to adjust them,2074.92074.9 how to make them learn from very, very few things that are2078.742078.74 nonetheless bigger than prompt, right. So if you want to teach2083.662083.66 GPT-3 a new trick, and it sort of exceeds the prompt size, this2088.85999999999972088.8599999999997 might be a very good way to go. If you don't want to go ahead2092.72092.7 and fine tune it, which would require much, much more data.2095.662096.94 What I don't really like about this paper is the fact that they2101.182101.42 say, oh, we just present the framework, it has its good2104.72104.7 things, but also it's bad things. They do actually implement2109.982109.98 something, which is to be commended. But there, I think2115.52115.5 the sort of comparison with the baseline is shaky, because it's2119.222119.22 not the an exact ablation of what they do. There would be2124.262124.3 would be better things. And their results, though, are2128.822129.3 convincing, apart from the fact that I suspect the data set2135.222135.22 creation was done by the same people who run the study. And2139.382139.38 since since as far as I can understand it, everything except2144.32144.3 for you know, the actual synonyms of words, everything2148.52148.5 else was done in a manual fashion, like coming up with2152.422152.42 prompts coming up with potential feedback. That would warrant2158.70000000000032158.7000000000003 some at least some caution, or maybe one would need to look at2163.382163.38 the exact data set. And as far as I understand it, that is2166.822166.82 actually available. So we're able to do that. Alright, that2170.58000000000042170.5800000000004 was it for this paper. Thanks for listening. Let me know what2174.862174.86 you think of this paper. It seems like a pretty neat idea.2179.462179.78 And I am excited to see what other people will expand on it.2185.022185.02 Bye bye.2196.7\"}"}